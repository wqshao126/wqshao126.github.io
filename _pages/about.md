---
permalink: /
title: " "
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  #- /about.html
---



<h2>
  Biography 
</h2>

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Wenqi Shao, CUHK, The Chinese University of Hong Kong">
<meta name="description" content="Wenqi Shao&#39;s home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
</head>
<body>

<p align = "justify"> 
I am a Research Scientist at Shanghai AI Lab. I got my Ph.D. degree from Multimedia Lab, the Chinese University of Hong Kong (CUHK) in 2022. 
During my Ph.D. period, I was supervised by <a href="https://www.ee.cuhk.edu.hk/~xgwang/">Prof. Xiaogang Wang</a>, <a href="http://luoping.me/">Prof. Ping Luo</a>, and <a href="https://www.ee.cuhk.edu.hk/~hsli/">Prof. Hongsheng Li</a>. 
Before that, I received bachelor's degree in School of Mathematics at University of Electronic Science and Technology of China (UESTC) in 2017, ranking 1/40. 
I was fortunate to have several interships in industry, such as Tencent ARC, Huawei Noah AI Foundation Group, and Sensetime Research. 
</p>

<p align = "justify"> 
My research interests lie in the pre-training, evaluation, applications of multimodal foundation models, as well as compression techniques and hardware codesign for large models. 
</p>

<p align = "justify"> 
<i> I am happy to work with self-motivated research interns at Shanghai AI lab. Feel free to send me an email if you are interested in the above topics. </i>
</p>

<!-- News
======
[06/2022] SFDA was accepted by ECCV 2022.
-->

<h2>
  News 
</h2>
<ul>
  <li>
    <p> [05/2024] One paper <a href="https://arxiv.org/abs/2401.02384"><b>ChartAssistant</b></a> in pre-training LVLMs on chart-related tasks was accepted to ACL'24 Findings. 
    </p>
  </li>
  <li>
    <p> [05/2024] Four papers including <a href="https://arxiv.org/pdf/2404.16006"><b>MMT-Bench</b></a> in evaluting LVLMs on a task map, <a href="https://arxiv.org/pdf/2403.02118"><b>ImplicitBench</b></a> in evaluating safety of T2I models, <a href="https://arxiv.org/pdf/2402.05935"><b>Sphinx-X</b></a> in pre-training powerful LVLMs, and <a href="https://arxiv.org/pdf/2402.16117"><b>RoboCodeX</b></a> in pre-training embodied foundation models were accepted to ICML'24.
    </p>
  </li>
  <li>
    <p> [03/2024] Two papers including <a href="https://arxiv.org/pdf/2402.09181"><b>OmniMedVQA</b></a> in evaluting LVLMs on medical domain and <a href="https://arxiv.org/pdf/2404.01342"><b>DiffAgent</b></a> in T2I model selection with LLMs were accepted to CVPR'24.
    </p>
  </li>
  <li>
    <p> [01/2024] Three papers including <a href="https://arxiv.org/pdf/2308.13137"><b>OmniQuant (Spotlight)</b></a> in quantizing LLMs,  <a href="https://arxiv.org/html/2402.16880v1"><b>BESA</b></a> in sparsifying LLMs, and <a href="https://arxiv.org/pdf/2310.08582"><b>Tree-Planner</b></a> in planning with LLMs were accepted to ICLR'24.
    </p>
  </li>
  <li>
    <p> [08/2023] One paper <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/687b7b2bdcc2ced577c0a989b44e7078-Paper-Conference.pdf"><b>EMMS </b></a> in multimodal multitask model selection was accepted to NeurIPS'23.
    </p>
  </li>
  <li>
    <p> [06/2023] Two papers including <a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.pdf"><b>DMMI (Oral)</b></a> in generalized refeering segmentation and <a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Chen_DiffRate__Differentiable_Compression_Rate_for_Efficient_Vision_Transformers_ICCV_2023_paper.pdf"><b>DiffRate</b></a> in ViT token compression  were accepted to ICCV'23.
    </p>
  </li>
  <li>
    <p> [03/2023] A whitening apporach <b>RCD</b> in real-time denoising for image and video was accepted to CVPR'23.
    </p>
  </li>
  <li>
    <p> [01/2023] A self-supervised framework for outdoor point cloud in autonomous driving <a href="https://arxiv.org/abs/2206.04028"> <b>CO3</b></a> was accepted to ICLR'23.
    </p>
  </li>
  <li>
    <p> [08/2022] Congrats! I have passed my Ph.D. Oral Defense.
    </p>
  </li>

  <li>
    <p> [06/2022] An effective model selection method <a href="https://arxiv.org/abs/2207.03036"> <b>SFDA</b></a> was accepted to ECCV 2022
    </p>
  </li>

  <li>
    <p> [06/2022] A self-supervised framework for point cloud in autonomous driving <a href="https://arxiv.org/abs/2206.04028"> <b>CO3</b></a> was released.
    </p>
  </li>

  <li>
    <p> [01/2022] A normalization method <a href="https://arxiv.org/abs/2112.02624"> <b>DTN</b></a> for ViTs was accepted to ICLR 2022.
    </p>
  </li>

  <li>
    <p> [08/2021] Theoretical analysis for channel pruning <a href="https://proceedings.neurips.cc/paper/2021/hash/87ae6fb631f7c8a627e8e28785d9992d-Abstract.html"> <b>CWDA</b></a> was accepted to NeurIPS 2021.
    </p>
  </li>

</ul>

<h2> Publications</h2>

  <h3>2022</h3>
  <ul>
  <li>
      CO^3: Cooperative Unsupervised 3D Representation Learning for Autonomous Driving, <br />
      R. Chen, Y. Mu, R. Xu, <b>W. Shao</b>, C. Jiang, H. Xu, Y. Qiao, Z. Li, P. Luo 
      <br /> arXiv preprint (<b>ICLR</b>), 2023. 
      [<a href="https://github.com/Runjian-Chen/CO3">Code</a>],
      [<a href="https://arxiv.org/abs/2206.04028">Paper</a>]
      <br />
    </li>
    <li>
      Not All Models Are Equal: Predicting Model Transferability in a Self-challenging Fisher Space, <br />
      <b> W. Shao </b>, X. Zhao, Y. Ge, Z. Zhang, L. Yang, X. Wang, Y. Shan, P. Luo. 
      <br /> European Conference on Computer Vision (<b>ECCV</b>), 2022. 
      [<a href="https://github.com/TencentARC/SFDA">Code</a>],
      [<a href="https://arxiv.org/abs/2207.03036">Paper</a>]
      <br />
    </li>
    <li>
      Dynamic Token Normalization Improves Vision Transformer, <br />
      <b>W. Shao</b>, Y. Ge, Z. Zhang, X. Xu, X. Wang, Y. Shan, P. Luo 
      <br /> International Conference on Learning Representation (<b>ICLR</b>), 2022. 
      [<a href="https://github.com/TencentARC/DTN">Code</a>],
      [<a href="https://arxiv.org/abs/2112.02624">Paper</a>]
      <br />
    </li>
    </ul>
    <h3>2021</h3>
    <ul>
    <li>
      Rethinking the pruning criteria for convolutional neural network, <br />
      Z. Huang*, <b>W. Shao*</b>, X. Wang, L. Lin, P. Luo
      <br /> Advances in Neural Information Processing (<b>NeurIPS</b>), 2021. 
      [<a href="https://proceedings.neurips.cc/paper/2021/file/87ae6fb631f7c8a627e8e28785d9992d-Paper.pdf">Paper</a>],
      [<a href="https://proceedings.neurips.cc/paper/2021/file/87ae6fb631f7c8a627e8e28785d9992d-Supplemental.pdf">Supp</a>]
      <br />
    </li>
      <br />
    <li>
      What makes for end-to-end object detection? <br />
      P. Sun, Y. Jiang, E. Xie, <b>W. Shao</b>, Z. Yuan, C. Wang, P. Luo
      <br /> International Conference on Machine Learning (<b>ICML</b>), 2021. 
      [<a href="https://proceedings.mlr.press/v139/sun21b.html?ref=https://githubhelp.com">Paper</a>]
      <br />
    </li>
      <br />
    <li>
      Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution, <br />
      Z. Zhang, <b>W. Shao</b>, J. Gu, X. Wang, P. Luo
      <br /> International Conference on Machine Learning (<b>ICML</b>), 2021. 
      [<a href="http://proceedings.mlr.press/v139/zhang21r.html">Paper</a>]
      <br />
    </li>
      <br />
    <li>
      BWCP: Probabilistic Learning-to-Prune Channels for ConvNets via Batch Whitening, <br />
      <b>W. Shao</b>, H. Yu, Z. Zhang, H. Xu, Z. Li, P. Luo
      <br /> arXiv preprint, Technical Report 2021. 
      [<a href="https://arxiv.org/abs/2206.04028">Paper</a>]
      <br />
    </li>
    </ul>
    <h3>2020</h3>
    <ul>
    <li>
      Channel equilibrium networks for learning deep representation, <br />
      <b>W. Shao</b>, S. Tang, X. Pan, P. Tan, X. Wang, P. Luo
      <br /> International Conference on Machine Learning (<b>ICML</b>), 2020. 
      [<a href="http://proceedings.mlr.press/v119/shao20a.html">Paper</a>]
      <br />
    </li>
    </ul>
    <h3>2019</h3>
    <ul>
    <li>
      SSN: Learning Sparse Switchable Normalization via SparsestMax, <br />
      <b>W. Shao</b>, J. Li, J. Ren, R. Zhang, X. Wang, P. Luo
      <br /> International Journal of Computer Vision (<b>IJCV</b>), Volume 128, 2019. 
      [<a href="https://link.springer.com/article/10.1007/s11263-019-01269-y">Paper</a>],
      [<a href="https://github.com/switchablenorms/Sparse_SwitchNorm">Code</a>]
      <br />
    </li>
      <br />
    <li>
      Towards understanding regularization in batch normalization, <br />
      P. Luo*, X. Wang*, <b>W. Shao*</b>, Z. Peng.
      <br /> International Conference on Learning Representation (<b>ICLR</b>), 2019. 
      [<a href="https://arxiv.org/abs/1809.00846">Paper</a>]
      <br />
      </li>
      <br />
    <li>
      SSN: Learning Sparse Switchable Normalization via SparsestMax, <br />
      <b>W. Shao</b>, T. Meng, J. Li, Y. Li, R. Zhang, X. Wang, P. Luo
      <br /> Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019. 
      [<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Shao_SSN_Learning_Sparse_Switchable_Normalization_via_SparsestMax_CVPR_2019_paper.html">Paper</a>],
      [<a href="https://github.com/switchablenorms/Sparse_SwitchNorm">Code</a>]
      <br />
      </li>
      <br />
    <li>
      Differentiable Learning-to-Group Channels via Groupable Convolutional Neural Networks, <br />
      Z. Zhang, J. Li, <b>W. Shao</b>, Z. Peng, R. Zhang, X. Wang, P. Luo
      <br /> International Conference on Computer Vision  (<b>ICCV</b>), 2019. 
      [<a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Zhang_Differentiable_Learning-to-Group_Channels_via_Groupable_Convolutional_Neural_Networks_ICCV_2019_paper.html">Paper</a>],
      <br />
      </li>
      <br />
    <li>
      Differentiable Dynamic Normalization for Learning Deep Representation, <br />
      P. Luo*, Z. Peng*, <b>W. Shao</b>, R. Zhang, J. Ren, P. Luo
      <br /> International Conference on Machine Learning (<b>ICML</b>), 2019. 
      [<a href="http://proceedings.mlr.press/v97/luo19a.html">Paper</a>],
      <br />
      </li>
    </ul>
     
<h2> Academic Activities </h2>
<ul>
  <li>
    <p> Co-organizer of Statistical Deep Learning Workshop on Computer Vision, ICCV 2019.
    </p>
  </li>
  <li>
    <p>
      Conference Reviewer of CVPR 2020, 2021; ICLR 2020, 2021, 2022; NeurIPS 2019, 2020, 2021, 2022; ICCV 2021.
      </p>
  </li>
  <li>
    <p>
      Invited Speaker in VALSE Workshop on Normalization Methods, VALSE, 2021
      </p>
  </li>
</ul>

<h2> Teaching </h2>
<ul>
  <li>
    <p> Teaching Assistant for <i> ELEG2401 Introduction to Embedded System</i>, Fall 2018, 2019, 2020, and 2021.
    </p>
  </li>
  <li>
    <p>
      Teaching Assistant for <i> ELEG1410 Linear Algebra and Vector Calculus for Engineers</i>, Spring 2019, 2021, and 2022.
      </p>
  </li>
  <li>
    <p>
      Teaching Assistant for <i> ELEG2450 Probability and Statistics for Engineers</i>, Spring 2020.
      </p>
  </li>
</ul>

</body></html>
