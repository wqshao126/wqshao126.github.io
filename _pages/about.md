---
permalink: /
title: " "
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  #- /about.html
---



<h2>
  Biography 
</h2>

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<link rel="shortcut icon" href="myIcon.ico">
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />

<meta name="keywords" content="Wenqi Shao, CUHK, The Chinese University of Hong Kong">
<meta name="description" content="Wenqi Shao&#39;s home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
</head>
<body>

<p align = "justify"> 
I am a Research Scientist at Shanghai AI Lab. I got my Ph.D. degree from Multimedia Lab, the Chinese University of Hong Kong (CUHK) in 2022. 
During my Ph.D. period, I was supervised by <a href="https://www.ee.cuhk.edu.hk/~xgwang/">Prof. Xiaogang Wang</a>, <a href="http://luoping.me/">Prof. Ping Luo</a>, and <a href="https://www.ee.cuhk.edu.hk/~hsli/">Prof. Hongsheng Li</a>. 
Before that, I received bachelor's degree in School of Mathematics at University of Electronic Science and Technology of China (UESTC) in 2017, ranking 1/40. 
I was fortunate to have several interships in industry, such as Tencent ARC, Huawei Noah AI Foundation Group, and Sensetime Research. My research interests lie in transfer learning of foundation models, co-design of networks and hardware accelerator, normalization methods in deep models, self-supervised representation learning, and compressing large-scale vision-language models. 
</p>

<p align = "justify"> 
<i> I am looking for research interns at Shanghai AI lab. Feel free to send me an email if you are interested in the above topics. </i>
</p>

<!-- News
======
[06/2022] SFDA was accepted by ECCV 2022.
-->

<h2>
  News 
</h2>
<ul>
  <li>
    <p> [03/2023] A whitening apporach <b>RCD</b> in real-time denoising for image and video was accepted to CVPR'23.
    </p>
  </li>
  <li>
    <p> [01/2023] A self-supervised framework for outdoor point cloud in autonomous driving <a href="https://arxiv.org/abs/2206.04028"> <b>CO3</b></a> was accepted to ICLR'23.
    </p>
  </li>
  <li>
    <p> [08/2022] Congrats! I have passed my Ph.D. Oral Defense.
    </p>
  </li>

  <li>
    <p> [06/2022] An effective model selection method <a href="https://arxiv.org/abs/2207.03036"> <b>SFDA</b></a> was accepted to ECCV 2022
    </p>
  </li>

  <li>
    <p> [06/2022] A self-supervised framework for point cloud in autonomous driving <a href="https://arxiv.org/abs/2206.04028"> <b>CO3</b></a> was released.
    </p>
  </li>

  <li>
    <p> [01/2022] A normalization method <a href="https://arxiv.org/abs/2112.02624"> <b>DTN</b></a> for ViTs was accepted to ICLR 2022.
    </p>
  </li>

  <li>
    <p> [08/2021] Theoretical analysis for channel pruning <a href="https://proceedings.neurips.cc/paper/2021/hash/87ae6fb631f7c8a627e8e28785d9992d-Abstract.html"> <b>CWDA</b></a> was accepted to NeurIPS 2021.
    </p>
  </li>

</ul>

<h2> Publications</h2>

  <h3>2022</h3>
  <ul>
  <li>
      CO^3: Cooperative Unsupervised 3D Representation Learning for Autonomous Driving, <br />
      R. Chen, Y. Mu, R. Xu, <b>W. Shao</b>, C. Jiang, H. Xu, Y. Qiao, Z. Li, P. Luo 
      <br /> arXiv preprint (<b>ICLR</b>), 2023. 
      [<a href="https://github.com/Runjian-Chen/CO3">Code</a>],
      [<a href="https://arxiv.org/abs/2206.04028">Paper</a>]
      <br />
    </li>
      <br />
    <li>
      Not All Models Are Equal: Predicting Model Transferability in a Self-challenging Fisher Space, <br />
      <b> W. Shao </b>, X. Zhao, Y. Ge, Z. Zhang, L. Yang, X. Wang, Y. Shan, P. Luo. 
      <br /> European Conference on Computer Vision (<b>ECCV</b>), 2022. 
      [<a href="https://github.com/TencentARC/SFDA">Code</a>],
      [<a href="https://arxiv.org/abs/2207.03036">Paper</a>]
      <br />
    </li>
      Dynamic Token Normalization Improves Vision Transformer, <br />
      <b>W. Shao</b>, Y. Ge, Z. Zhang, X. Xu, X. Wang, Y. Shan, P. Luo 
      <br /> International Conference on Learning Representation (<b>ICLR</b>), 2022. 
      [<a href="https://github.com/TencentARC/DTN">Code</a>],
      [<a href="https://arxiv.org/abs/2112.02624">Paper</a>]
      <br />
    </li>
    </ul>
    <h3>2021</h3>
    <ul>
    <li>
      Rethinking the pruning criteria for convolutional neural network, <br />
      Z. Huang*, <b>W. Shao*</b>, X. Wang, L. Lin, P. Luo
      <br /> Advances in Neural Information Processing (<b>NeurIPS</b>), 2021. 
      [<a href="https://proceedings.neurips.cc/paper/2021/file/87ae6fb631f7c8a627e8e28785d9992d-Paper.pdf">Paper</a>],
      [<a href="https://proceedings.neurips.cc/paper/2021/file/87ae6fb631f7c8a627e8e28785d9992d-Supplemental.pdf">Supp</a>]
      <br />
    </li>
      <br />
    <li>
      What makes for end-to-end object detection? <br />
      P. Sun, Y. Jiang, E. Xie, <b>W. Shao</b>, Z. Yuan, C. Wang, P. Luo
      <br /> International Conference on Machine Learning (<b>ICML</b>), 2021. 
      [<a href="https://proceedings.mlr.press/v139/sun21b.html?ref=https://githubhelp.com">Paper</a>]
      <br />
    </li>
      <br />
    <li>
      Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution, <br />
      Z. Zhang, <b>W. Shao</b>, J. Gu, X. Wang, P. Luo
      <br /> International Conference on Machine Learning (<b>ICML</b>), 2021. 
      [<a href="http://proceedings.mlr.press/v139/zhang21r.html">Paper</a>]
      <br />
    </li>
      <br />
    <li>
      BWCP: Probabilistic Learning-to-Prune Channels for ConvNets via Batch Whitening, <br />
      <b>W. Shao</b>, H. Yu, Z. Zhang, H. Xu, Z. Li, P. Luo
      <br /> arXiv preprint, Technical Report 2021. 
      [<a href="https://arxiv.org/abs/2206.04028">Paper</a>]
      <br />
    </li>
    </ul>
    <h3>2020</h3>
    <ul>
    <li>
      Channel equilibrium networks for learning deep representation, <br />
      <b>W. Shao</b>, S. Tang, X. Pan, P. Tan, X. Wang, P. Luo
      <br /> International Conference on Machine Learning (<b>ICML</b>), 2020. 
      [<a href="http://proceedings.mlr.press/v119/shao20a.html">Paper</a>]
      <br />
    </li>
    </ul>
    <h3>2019</h3>
    <ul>
    <li>
      SSN: Learning Sparse Switchable Normalization via SparsestMax, <br />
      <b>W. Shao</b>, J. Li, J. Ren, R. Zhang, X. Wang, P. Luo
      <br /> International Journal of Computer Vision (<b>IJCV</b>), Volume 128, 2019. 
      [<a href="https://link.springer.com/article/10.1007/s11263-019-01269-y">Paper</a>],
      [<a href="https://github.com/switchablenorms/Sparse_SwitchNorm">Code</a>]
      <br />
    </li>
      <br />
    <li>
      Towards understanding regularization in batch normalization, <br />
      P. Luo*, X. Wang*, <b>W. Shao*</b>, Z. Peng.
      <br /> International Conference on Learning Representation (<b>ICLR</b>), 2019. 
      [<a href="https://arxiv.org/abs/1809.00846">Paper</a>]
      <br />
      </li>
      <br />
    <li>
      SSN: Learning Sparse Switchable Normalization via SparsestMax, <br />
      <b>W. Shao</b>, T. Meng, J. Li, Y. Li, R. Zhang, X. Wang, P. Luo
      <br /> Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019. 
      [<a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Shao_SSN_Learning_Sparse_Switchable_Normalization_via_SparsestMax_CVPR_2019_paper.html">Paper</a>],
      [<a href="https://github.com/switchablenorms/Sparse_SwitchNorm">Code</a>]
      <br />
      </li>
      <br />
    <li>
      Differentiable Learning-to-Group Channels via Groupable Convolutional Neural Networks, <br />
      Z. Zhang, J. Li, <b>W. Shao</b>, Z. Peng, R. Zhang, X. Wang, P. Luo
      <br /> International Conference on Computer Vision  (<b>ICCV</b>), 2019. 
      [<a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Zhang_Differentiable_Learning-to-Group_Channels_via_Groupable_Convolutional_Neural_Networks_ICCV_2019_paper.html">Paper</a>],
      <br />
      </li>
      <br />
    <li>
      Differentiable Dynamic Normalization for Learning Deep Representation, <br />
      P. Luo*, Z. Peng*, <b>W. Shao</b>, R. Zhang, J. Ren, P. Luo
      <br /> International Conference on Machine Learning (<b>ICML</b>), 2019. 
      [<a href="http://proceedings.mlr.press/v97/luo19a.html">Paper</a>],
      <br />
      </li>
    </ul>
     
<h2> Academic Activities </h2>
<ul>
  <li>
    <p> Co-organizer of Statistical Deep Learning Workshop on Computer Vision, ICCV 2019.
    </p>
  </li>
  <li>
    <p>
      Conference Reviewer of CVPR 2020, 2021; ICLR 2020, 2021, 2022; NeurIPS 2019, 2020, 2021, 2022; ICCV 2021.
      </p>
  </li>
  <li>
    <p>
      Invited Speaker in VALSE Workshop on Normalization Methods, VALSE, 2021
      </p>
  </li>
</ul>

<h2> Teaching </h2>
<ul>
  <li>
    <p> Teaching Assistant for <i> ELEG2401 Introduction to Embedded System</i>, Fall 2018, 2019, 2020, and 2021.
    </p>
  </li>
  <li>
    <p>
      Teaching Assistant for <i> ELEG1410 Linear Algebra and Vector Calculus for Engineers</i>, Spring 2019, 2021, and 2022.
      </p>
  </li>
  <li>
    <p>
      Teaching Assistant for <i> ELEG2450 Probability and Statistics for Engineers</i>, Spring 2020.
      </p>
  </li>
</ul>

</body></html>
